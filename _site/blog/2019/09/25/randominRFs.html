<h1 id="1-the-random-in-random-forests">1. The Random in Random Forests</h1>
<p>Random forests (RF) are my default starting point for most of the data science I do at Texas A&amp;M. Random forests are the honey badgers of machine learning. <strong>They don’t care</strong>.</p>

<p><img src="http://giphygifs.s3.amazonaws.com/media/f8k6R32qjJGV2/giphy.gif" alt="ChessUrl" title="RF doesn't care" /></p>

<p>They don’t care about normalizing to the mean and standard deviation. They don’t care about hyperparameters or tuning. You may not be able to get that last 1% of accuracy versus other methods, but RFs are easy to understand and visualize.</p>

<h2 id="12-an-observation-for-motivation">1.2 An Observation for Motivation</h2>
<p>There’s this prevailing idea in a number of <a href="https://ieeexplore.ieee.org/document/598994">foundational</a> <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">papers</a> about Random Forests.</p>

<blockquote>
  <p>Average a bunch of <em>bad</em> trees, and you get a <em>good</em> prediction.</p>
</blockquote>

<p>From a purely intuitive sense, that’s a weird concept. We show the machine lots of different data sets, and ask it to make the best possible prediction, which ends up being lots of not so good predictions. Let’s take a closer look with a really simple <a href="https://www.kaggle.com/aungpyaeap/fish-market">dataset</a> and the <a href="https://www.fast.ai/">fastai</a> library.</p>

<hr />
<p>Quick and shameless plug for <a href="https://www.fast.ai/">fastai</a>. If you’re even a little bit interested in using ML, this is such a great resource. The top down lecturing approach is much more intuitive than the statistics up approach I’ve seen at university. Lots of discussion about broader impacts of the technology too. This whole post is based on something I’ve learned while working through the fastai courses.</p>

<h1 id="2-setup">2. Setup</h1>
<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>
<!-- 
    <!-- The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload -->

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.imports</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.structured</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">pandas_summary</span> <span class="kn">import</span> <span class="n">DataFrameSummary</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">graphviz</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Setup Complete."</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="21-read-data">2.1 Read data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PATH</span> <span class="o">=</span> <span class="s">"data/fish-market/"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/fish-market/Fish.csv'</span><span class="p">)</span> <span class="c1">#read the raw data
</span><span class="n">df_raw</span><span class="o">.</span><span class="n">head</span><span class="p">()</span> <span class="c1">#display the first few rows, verification
</span></code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Weight</th>
      <th>Length1</th>
      <th>Length2</th>
      <th>Length3</th>
      <th>Height</th>
      <th>Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bream</td>
      <td>242.0</td>
      <td>23.2</td>
      <td>25.4</td>
      <td>30.0</td>
      <td>11.5200</td>
      <td>4.0200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bream</td>
      <td>290.0</td>
      <td>24.0</td>
      <td>26.3</td>
      <td>31.2</td>
      <td>12.4800</td>
      <td>4.3056</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bream</td>
      <td>340.0</td>
      <td>23.9</td>
      <td>26.5</td>
      <td>31.1</td>
      <td>12.3778</td>
      <td>4.6961</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bream</td>
      <td>363.0</td>
      <td>26.3</td>
      <td>29.0</td>
      <td>33.5</td>
      <td>12.7300</td>
      <td>4.4555</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bream</td>
      <td>430.0</td>
      <td>26.5</td>
      <td>29.0</td>
      <td>34.0</td>
      <td>12.4440</td>
      <td>5.1340</td>
    </tr>
  </tbody>
</table>
</div>

<p>This is a happy dataset. We’ve got 7 species of fish with relevant measurements. Here’s a Bream fish for example. We can target weight as our output variable for the time being.
<img src="https://cdn.pixabay.com/photo/2018/05/17/16/33/sea-bream-3409033_960_720.png" alt="alt text" title="Bream Fish" />
This is an especially nice set because there’s no time interaction between the variables. Variable interaction alone is worth a whole separate post but  note that most datasets need more feature engineering before they can be learned. Since this is such an easy data set, I’m not going to focus on getting maximum accuracy, but rather keeping the forest small so we can visualize it easily.</p>

<h2 id="22-prepare-data">2.2 Prepare data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_raw</span><span class="o">.</span><span class="n">Weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">Weight</span><span class="p">)</span> <span class="c1">#convert target variable to log scale, usually plots nicer
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s">'tmp'</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#create a folder for raw feather files
</span><span class="n">df_raw</span><span class="o">.</span><span class="n">to_feather</span><span class="p">(</span><span class="s">'tmp/fish-raw'</span><span class="p">)</span> <span class="c1">#write raw data to feather so we don't have to keep reading a slow csv file
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span><span class="s">'tmp/fish-raw'</span><span class="p">)</span> <span class="c1">#sushis and sashimis
</span><span class="n">df_raw</span><span class="o">.</span><span class="n">head</span><span class="p">()</span> <span class="c1">#make sure the feather was read correctly
</span></code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Weight</th>
      <th>Length1</th>
      <th>Length2</th>
      <th>Length3</th>
      <th>Height</th>
      <th>Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bream</td>
      <td>5.488938</td>
      <td>23.2</td>
      <td>25.4</td>
      <td>30.0</td>
      <td>11.5200</td>
      <td>4.0200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bream</td>
      <td>5.669881</td>
      <td>24.0</td>
      <td>26.3</td>
      <td>31.2</td>
      <td>12.4800</td>
      <td>4.3056</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bream</td>
      <td>5.828946</td>
      <td>23.9</td>
      <td>26.5</td>
      <td>31.1</td>
      <td>12.3778</td>
      <td>4.6961</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bream</td>
      <td>5.894403</td>
      <td>26.3</td>
      <td>29.0</td>
      <td>33.5</td>
      <td>12.7300</td>
      <td>4.4555</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bream</td>
      <td>6.063785</td>
      <td>26.5</td>
      <td>29.0</td>
      <td>34.0</td>
      <td>12.4440</td>
      <td>5.1340</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="23-visualize-the-data">2.3 Visualize the data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> <span class="c1">#visualize the initial data
</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">Length1</span><span class="p">)</span> 
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Length1'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">Length2</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Length2'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">Length3</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Length3'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">Height</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Height'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">Width</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Width'</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">Weight</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Weight'</span><span class="p">)</span>
</code></pre></div></div>
<!-- 



    Text(0.5, 1.0, 'Weight') -->

<p><img src="/assets/images/output_12_1.png" alt="png" /></p>

<p>Super manageable data set. You could probably get away with some kind of <a href="https://www.kaggle.com/akdagmelih/multiplelinear-regression-fish-weight-estimation">5 dimension linear hyperplane</a> if you wanted.</p>

<h2 id="24-spit-data-into-test-and-training-sets">2.4 Spit data into test and training sets</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_cats</span><span class="p">(</span><span class="n">df_raw</span><span class="p">)</span> <span class="c1">#enumerate categorical variables
</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">nas</span> <span class="o">=</span> <span class="n">proc_df</span><span class="p">(</span><span class="n">df_raw</span><span class="p">,</span> <span class="s">'Weight'</span><span class="p">)</span> <span class="c1">#split target variable from training data
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">msk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.8</span> <span class="c1">#set ratio for training and test set sizes (80% of sample in training)
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">msk</span><span class="p">]</span> 
<span class="n">y_train</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">msk</span><span class="p">]</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">msk</span><span class="p">]</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">msk</span><span class="p">]</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">shape</span> <span class="c1">#verify sizes of datasets
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>((135, 6), (135,), (24, 6), (24,))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span> <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">print_score</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">rmse</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">rmse</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">),</span> <span class="n">y_valid</span><span class="p">),</span>
                <span class="n">m</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)]</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s">'oob_score_'</span><span class="p">):</span> <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="3-train-the-model">3. Train the Model</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span> <span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1">#limit the size of the tree for visualization
</span><span class="o">%</span><span class="n">time</span> <span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">print_score</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Wall time: 114 ms
[0.105640573238319, 0.18335970391783124, 0.9936340002864559, 0.9798625436302886]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">"PATH"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">os</span><span class="o">.</span><span class="n">pathsep</span> <span class="o">+</span> <span class="s">'C:/Program Files (x86)/Graphviz2.38/bin'</span>
</code></pre></div></div>

<h1 id="4-analysis-and-results">4. Analysis and Results</h1>
<p>Let’s take a look at a single tree visually. Notice that this particular tree is splitting on Length3, the diagonal length of the fish, a number of times. This suggests that variable is particularly important. The specifics of the tree aren’t super critical here, it’s mostly a nice visualization.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span><span class="o">=</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                      <span class="n">special_characters</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rotate</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="n">graph</span>
</code></pre></div></div>

<p><img src="/assets/images/output_22_0.svg" alt="svg" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">t</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">estimators_</span><span class="p">])</span>
<span class="n">final_out</span><span class="o">=</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span> <span class="n">y_valid</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># this is the key metric for the point I'm trying to make
</span><span class="n">final_out</span> <span class="c1">#an object with each of the predictions for a single sample, combined with the final estimate and the truth
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([5.64993, 5.85184, 5.65803, 5.56792, 5.57952, 5.57955, 5.78348, 5.34795, 5.88255, 5.80122]),
 5.670200821131428,
 5.66988092298052)
</code></pre></div></div>

<p>There’s the result. Let’s look at this graphically.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">t</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">estimators_</span><span class="p">])</span>
<span class="n">final_out</span><span class="o">=</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">final_out</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_out</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">final_out</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_out</span><span class="p">,</span><span class="n">y_valid</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1">#CS folks, how to concat scalars w/ 1D array?
</span><span class="n">final_delta</span><span class="o">=</span><span class="n">final_out</span><span class="o">-</span><span class="n">y_valid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'T1'</span><span class="p">,</span> <span class="s">'T2'</span><span class="p">,</span> <span class="s">'T3'</span><span class="p">,</span> <span class="s">'T4'</span><span class="p">,</span> <span class="s">'T5'</span><span class="p">,</span><span class="s">'T6'</span><span class="p">,</span> <span class="s">'T7'</span><span class="p">,</span> <span class="s">'T8'</span><span class="p">,</span> <span class="s">'T9'</span><span class="p">,</span> <span class="s">'T10'</span><span class="p">,</span><span class="s">'Forest'</span><span class="p">,</span><span class="s">'Truth'</span><span class="p">]</span>
</code></pre></div></div>

<h1 id="5-main-conclusions">5. Main Conclusions</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">zorder</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">final_out</span><span class="p">)),</span> <span class="n">final_out</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'steelblue'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">final_out</span><span class="p">)))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">zorder</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">final_delta</span><span class="p">)),</span> <span class="n">final_delta</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'tomato'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">final_delta</span><span class="p">)))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">labels</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="/assets/images/output_27_0.png" alt="png" /></p>

<!-- 
```python
def color_table(val):
    """
    Takes a scalar and returns a string with
    the css property `'color: red'` for negative
    strings, black otherwise.
    """
    if val < 0:
        color = 'red' 
    elif 0 < val < .01:
        color = 'blue'
    elif 0 < val < 1:
        color = 'green'
    else:
        color = 'black'
    return 'color: %s' % color
``` -->

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/fish-market/results.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">result_table</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="n">color_table</span><span class="p">)</span>
<span class="n">s</span>
</code></pre></div></div>

<style type="text/css">
    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow0_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow0_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow0_col2 {
            color:  red;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow1_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow1_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow1_col2 {
            color:  green;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow2_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow2_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow2_col2 {
            color:  red;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow3_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow3_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow3_col2 {
            color:  red;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow4_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow4_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow4_col2 {
            color:  red;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow5_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow5_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow5_col2 {
            color:  red;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow6_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow6_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow6_col2 {
            color:  green;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow7_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow7_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow7_col2 {
            color:  red;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow8_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow8_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow8_col2 {
            color:  green;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow9_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow9_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow9_col2 {
            color:  green;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow10_col0 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow10_col1 {
            color:  black;
        }    #T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow10_col2 {
            color:  blue;
        }</style>
<table id="T_0fae72ac_ef62_11e9_9c38_001583f72bbf"><thead>    <tr>        <th class="blank level0"></th>        <th class="col_heading level0 col0">Prediction</th>        <th class="col_heading level0 col1">Truth</th>        <th class="col_heading level0 col2">delta_truth</th>    </tr></thead><tbody>
                <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row0" class="row_heading level0 row0">Tree 1</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow0_col0" class="data row0 col0">5.64993</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow0_col1" class="data row0 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow0_col2" class="data row0 col2">-0.0199509</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row1" class="row_heading level0 row1">Tree 2</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow1_col0" class="data row1 col0">5.85184</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow1_col1" class="data row1 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow1_col2" class="data row1 col2">0.181959</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row2" class="row_heading level0 row2">Tree 3</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow2_col0" class="data row2 col0">5.65803</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow2_col1" class="data row2 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow2_col2" class="data row2 col2">-0.0118509</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row3" class="row_heading level0 row3">Tree 4</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow3_col0" class="data row3 col0">5.56792</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow3_col1" class="data row3 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow3_col2" class="data row3 col2">-0.101961</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row4" class="row_heading level0 row4">Tree 5</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow4_col0" class="data row4 col0">5.57952</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow4_col1" class="data row4 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow4_col2" class="data row4 col2">-0.0903609</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row5" class="row_heading level0 row5">Tree 6</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow5_col0" class="data row5 col0">5.57955</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow5_col1" class="data row5 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow5_col2" class="data row5 col2">-0.0903309</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row6" class="row_heading level0 row6">Tree 7</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow6_col0" class="data row6 col0">5.78348</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow6_col1" class="data row6 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow6_col2" class="data row6 col2">0.113599</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row7" class="row_heading level0 row7">Tree 8</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow7_col0" class="data row7 col0">5.34795</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow7_col1" class="data row7 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow7_col2" class="data row7 col2">-0.321931</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row8" class="row_heading level0 row8">Tree 9</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow8_col0" class="data row8 col0">5.88255</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow8_col1" class="data row8 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow8_col2" class="data row8 col2">0.212669</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row9" class="row_heading level0 row9">Tree 10</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow9_col0" class="data row9 col0">5.80122</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow9_col1" class="data row9 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow9_col2" class="data row9 col2">0.131339</td>
            </tr>
            <tr>
                        <th id="T_0fae72ac_ef62_11e9_9c38_001583f72bbflevel0_row10" class="row_heading level0 row10">Average (Forest)</th>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow10_col0" class="data row10 col0">5.6702</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow10_col1" class="data row10 col1">5.66988</td>
                        <td id="T_0fae72ac_ef62_11e9_9c38_001583f72bbfrow10_col2" class="data row10 col2">0.000319898</td>
            </tr>
    </tbody></table>

<p>We’re looking at a single estimate of the weight for our forest with 10 trees in it. The first 10 bars show the weight prediction of a <strong>single</strong> fish. The 11th bar is the average of all the predicted weights from our trees, which makes the forest. The last bar is the actual weight.</p>

<p>Notice every tree is a little off. Tree 8 is predicting way too low, while trees 2, 9, and 10 are predicting too high. Think of this as each tree exploiting a different trend in the data.</p>

<p>However, the average across all trees gives an estimate that is incredibly accurate. So much so that in this example the difference between the true weight and the forest predicted weight is invisible on the second plot.</p>

<p>Let’s revisit our initial motivation:</p>

<blockquote>
  <p>Average a bunch of <em>bad</em> trees, and you get a <em>good</em> prediction.</p>
</blockquote>

<p>Perhaps this statement is misleading. Maybe what I really mean to say is:</p>
<blockquote>
  <p>The average of random error is <strong>zero</strong>.</p>
</blockquote>

<p>If all the trees exploit different paths through the data, the model is generalizable and yields the best prediction. It is <em>randomly</em> exploring the trends in the data, putting the random in random forest. You can download this notebook <a href="https://drive.google.com/file/d/1oUDjM0dYWXoESoxgQIwU1MeaQiOKMlBM/view?usp=sharing">here</a>.</p>

